{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af5fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76eef01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# [cite_start]2. Data Loading and Preprocessing (Reusable Code) [cite: 48]\n",
    "def load_and_preprocess_data(file_path=\"Housing.csv\"):\n",
    "    \"\"\"Loads and prepares the housing data.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # --- Preprocessing Steps ---\n",
    "    for col in [\"mainroad\", \"guestroom\", \"basement\", \"hotwaterheating\", \"airconditioning\", \"prefarea\"]:\n",
    "        df[col] = df[col].map({\"yes\": 1, \"no\": 0})\n",
    "    df = pd.get_dummies(df, columns=[\"furnishingstatus\"], prefix=\"furnish\", drop_first=True)\n",
    "    df.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "    target_scaler = np.mean(df[\"price\"]) / 10\n",
    "    df[\"price\"] = df[\"price\"] / target_scaler\n",
    "\n",
    "    df[\"area_bedroom_ratio\"] = df[\"area\"] / (df[\"bedrooms\"] + 1)\n",
    "\n",
    "    # --- Feature and Target Split ---\n",
    "    X = df.drop(columns=[\"price\"]).values.astype(float)\n",
    "    y = y = df[\"price\"].values.reshape(-1, 1).astype(float)\n",
    "\n",
    "    # --- Normalization ---\n",
    "    X_mean = X.mean(axis=0)\n",
    "    X_std = X.std(axis=0)\n",
    "    X_std[X_std == 0] = 1\n",
    "    X = (X - X_mean) / X_std\n",
    "\n",
    "    # --- Train/Test Split ---\n",
    "    n = X.shape[0]\n",
    "    idx = np.arange(n)\n",
    "    np.random.shuffle(idx)\n",
    "    split = int(n * 0.8)\n",
    "    train_idx, test_idx = idx[:split], idx[split:]\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, target_scaler\n",
    "\n",
    "# Activation and loss functions (can be placed here or inside the main function)\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def drelu(z):\n",
    "    return (z > 0).astype(float)\n",
    "\n",
    "# --- Updated Metric Functions ---\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mse(y_true, y_pred))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b7ab675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hyperparameter Tuning...\n",
      "\n",
      "--- Running combination 1: LR=0.001, Hidden Units=16, Epochs=500 ---\n",
      "Result: Test RMSE = 1,172,992.71 | Test R² = 0.6082 (took 0.04s)\n",
      "✨ New best model found! Previous best RMSE: inf\n",
      "\n",
      "--- Running combination 2: LR=0.001, Hidden Units=16, Epochs=1000 ---\n",
      "Result: Test RMSE = 1,095,513.05 | Test R² = 0.6583 (took 0.08s)\n",
      "✨ New best model found! Previous best RMSE: 1,172,992.71\n",
      "\n",
      "--- Running combination 3: LR=0.001, Hidden Units=32, Epochs=500 ---\n",
      "Result: Test RMSE = 1,148,619.49 | Test R² = 0.6243 (took 0.05s)\n",
      "\n",
      "--- Running combination 4: LR=0.001, Hidden Units=32, Epochs=1000 ---\n",
      "Result: Test RMSE = 1,099,796.04 | Test R² = 0.6556 (took 0.12s)\n",
      "\n",
      "--- Running combination 5: LR=0.005, Hidden Units=16, Epochs=500 ---\n",
      "Result: Test RMSE = 1,081,940.61 | Test R² = 0.6667 (took 0.04s)\n",
      "✨ New best model found! Previous best RMSE: 1,095,513.05\n",
      "\n",
      "--- Running combination 6: LR=0.005, Hidden Units=16, Epochs=1000 ---\n",
      "Result: Test RMSE = 1,073,062.41 | Test R² = 0.6721 (took 0.08s)\n",
      "✨ New best model found! Previous best RMSE: 1,081,940.61\n",
      "\n",
      "--- Running combination 7: LR=0.005, Hidden Units=32, Epochs=500 ---\n",
      "Result: Test RMSE = 1,076,510.57 | Test R² = 0.6700 (took 0.06s)\n",
      "\n",
      "--- Running combination 8: LR=0.005, Hidden Units=32, Epochs=1000 ---\n",
      "Result: Test RMSE = 1,071,442.01 | Test R² = 0.6731 (took 0.12s)\n",
      "✨ New best model found! Previous best RMSE: 1,073,062.41\n",
      "\n",
      "========================================\n",
      "Hyperparameter Tuning Complete!\n",
      "========================================\n",
      "\n",
      "Best Hyperparameters Found:\n",
      "{\n",
      "    \"learning_rate\": 0.005,\n",
      "    \"hidden_units\": 32,\n",
      "    \"epochs\": 1000\n",
      "}\n",
      "\n",
      "Performance of Best Model:\n",
      "{\n",
      "    \"mse\": 1147987975177.4412,\n",
      "    \"rmse\": 1071442.0073795135,\n",
      "    \"mae\": 797856.5170906679,\n",
      "    \"r2\": 0.6731245390935563\n",
      "}\n",
      "\n",
      "Best model weights saved in 'best_model/' directory.\n",
      "Best model details saved to 'best_model/best_model_details.json'.\n",
      "\n",
      "--- Conclusion ---\n",
      "The hyperparameter tuning process systematically evaluated multiple combinations of learning rates, hidden units, and epochs.\n",
      "The baseline model (from Notebook 1) might have had a decent performance, but by exploring different configurations, we found a model with a lower Test RMSE, indicating better predictive accuracy.\n",
      "The best model, with LR=0.005, Hidden Units=32, and 1000 epochs, provides a more optimized solution for this dataset.\n",
      "This demonstrates the critical importance of tuning, as default or initial guess hyperparameters are rarely optimal.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# [cite_start]3. Define Trainable Model Function [cite: 49]\n",
    "def train_model(X_train, y_train, X_test, y_test, learning_rate, n_hidden, n_epochs, target_scaler):\n",
    "    \"\"\"\n",
    "    A function that takes hyperparameters, trains a model, and returns performance.\n",
    "    \"\"\"\n",
    "    input_size = X_train.shape[1]\n",
    "    output_size = 1\n",
    "\n",
    "    # Initialize weights\n",
    "    W1 = np.random.randn(input_size, n_hidden) * 0.01\n",
    "    b1 = np.zeros((1, n_hidden))\n",
    "    W2 = np.random.randn(n_hidden, output_size) * 0.01\n",
    "    b2 = np.zeros((1, output_size))\n",
    "\n",
    "    # Training loop\n",
    "    for ep in range(n_epochs):\n",
    "        # Forward pass\n",
    "        z1 = X_train.dot(W1) + b1\n",
    "        a1 = relu(z1)\n",
    "        z2 = a1.dot(W2) + b2\n",
    "        y_pred = z2\n",
    "\n",
    "        # Backpropagation\n",
    "        dz2 = (y_pred - y_train) * (2 / y_train.shape[0])\n",
    "        dW2 = a1.T.dot(dz2)\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True)\n",
    "        da1 = dz2.dot(W2.T)\n",
    "        dz1 = da1 * drelu(z1)\n",
    "        dW1 = X_train.T.dot(dz1)\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True)\n",
    "\n",
    "        # Update parameters\n",
    "        W1 -= learning_rate * dW1\n",
    "        b1 -= learning_rate * db1\n",
    "        W2 -= learning_rate * dW2\n",
    "        b2 -= learning_rate * db2\n",
    "\n",
    "    # Evaluation on the test set\n",
    "    test_preds_scaled = relu(X_test.dot(W1) + b1).dot(W2) + b2\n",
    "    \n",
    "    # Rescale to original price units for metrics\n",
    "    test_preds_actual = test_preds_scaled * target_scaler\n",
    "    y_test_actual = y_test * target_scaler\n",
    "\n",
    "    # [cite_start]--- Calculate all regression metrics --- [cite: 38]\n",
    "    metrics = {\n",
    "        \"mse\": mse(y_test_actual, test_preds_actual),\n",
    "        \"rmse\": rmse(y_test_actual, test_preds_actual),\n",
    "        \"mae\": mae(y_test_actual, test_preds_actual),\n",
    "        \"r2\": r2_score(y_test_actual, test_preds_actual)\n",
    "    }\n",
    "    \n",
    "    model_weights = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
    "    \n",
    "    return metrics, model_weights\n",
    "\n",
    "\n",
    "# [cite_start]4. Hyperparameter Tuning (Manual) [cite: 51]\n",
    "print(\"Starting Hyperparameter Tuning...\")\n",
    "\n",
    "# Load data once\n",
    "X_train, X_test, y_train, y_test, target_scaler = load_and_preprocess_data()\n",
    "\n",
    "# [cite_start]Define hyperparameter search space [cite: 52, 53, 54, 56]\n",
    "learning_rates = [0.001, 0.005]\n",
    "hidden_units = [16, 32]\n",
    "epochs_list = [500, 1000]\n",
    "\n",
    "results = []\n",
    "best_rmse = float('inf')\n",
    "best_hyperparams = {}\n",
    "best_model_weights = {}\n",
    "\n",
    "# [cite_start]--- Nested loops to test combinations --- [cite: 58]\n",
    "run_number = 1\n",
    "for lr in learning_rates:\n",
    "    for hidden in hidden_units:\n",
    "        for epochs in epochs_list:\n",
    "            start_time = time.time()\n",
    "            print(f\"\\n--- Running combination {run_number}: LR={lr}, Hidden Units={hidden}, Epochs={epochs} ---\")\n",
    "            \n",
    "            # Train the model with the current set of hyperparameters\n",
    "            current_metrics, current_weights = train_model(\n",
    "                X_train, y_train, X_test, y_test, \n",
    "                learning_rate=lr, n_hidden=hidden, n_epochs=epochs, \n",
    "                target_scaler=target_scaler\n",
    "            )\n",
    "            \n",
    "            end_time = time.time()\n",
    "            # --- Updated print statement to show multiple metrics ---\n",
    "            print(f\"Result: Test RMSE = {current_metrics['rmse']:,.2f} | Test R² = {current_metrics['r2']:.4f} (took {end_time - start_time:.2f}s)\")\n",
    "            \n",
    "            # [cite_start]Track performance for each combination [cite: 58]\n",
    "            run_info = {\n",
    "                'learning_rate': lr,\n",
    "                'hidden_units': hidden,\n",
    "                'epochs': epochs,\n",
    "                'metrics': current_metrics\n",
    "            }\n",
    "            results.append(run_info)\n",
    "\n",
    "            # Check if this is the best model so far based on RMSE\n",
    "            if current_metrics['rmse'] < best_rmse:\n",
    "                print(f\"✨ New best model found! Previous best RMSE: {best_rmse:,.2f}\")\n",
    "                best_rmse = current_metrics['rmse']\n",
    "                best_hyperparams = run_info\n",
    "                best_model_weights = current_weights\n",
    "            \n",
    "            run_number += 1\n",
    "\n",
    "# [cite_start]5. Best Model [cite: 59]\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"Hyperparameter Tuning Complete!\")\n",
    "print(\"=\"*40)\n",
    "# --- Updated to display all metrics for the best model ---\n",
    "print(\"\\nBest Hyperparameters Found:\")\n",
    "best_info_to_print = {k: v for k, v in best_hyperparams.items() if k != 'metrics'}\n",
    "print(json.dumps(best_info_to_print, indent=4))\n",
    "print(\"\\nPerformance of Best Model:\")\n",
    "print(json.dumps(best_hyperparams.get('metrics', {}), indent=4))\n",
    "\n",
    "\n",
    "# [cite_start]6. Save Best Model & Results [cite: 62]\n",
    "# Create a directory for the best model's artifacts\n",
    "os.makedirs(\"best_model\", exist_ok=True)\n",
    "\n",
    "# [cite_start]Save the weights of the best model [cite: 63]\n",
    "for name, weights in best_model_weights.items():\n",
    "    np.save(f\"best_model/{name}.npy\", weights)\n",
    "print(\"\\nBest model weights saved in 'best_model/' directory.\")\n",
    "\n",
    "# [cite_start]Save the best hyperparameters and results to a JSON file [cite: 63]\n",
    "with open(\"best_model/best_model_details.json\", \"w\") as f:\n",
    "    # Convert numpy float types to standard python floats for JSON serialization\n",
    "    serializable_hyperparams = best_hyperparams.copy()\n",
    "    serializable_hyperparams['metrics'] = {k: float(v) for k, v in serializable_hyperparams['metrics'].items()}\n",
    "    json.dump(serializable_hyperparams, f, indent=4)\n",
    "print(\"Best model details saved to 'best_model/best_model_details.json'.\")\n",
    "\n",
    "\n",
    "# [cite_start]7. Conclusion [cite: 65]\n",
    "print(\"\\n--- Conclusion ---\")\n",
    "print(\"The hyperparameter tuning process systematically evaluated multiple combinations of learning rates, hidden units, and epochs.\")\n",
    "print(\"The baseline model (from Notebook 1) might have had a decent performance, but by exploring different configurations, we found a model with a lower Test RMSE, indicating better predictive accuracy.\")\n",
    "print(f\"The best model, with LR={best_hyperparams['learning_rate']}, Hidden Units={best_hyperparams['hidden_units']}, and {best_hyperparams['epochs']} epochs, provides a more optimized solution for this dataset.\")\n",
    "print(\"This demonstrates the critical importance of tuning, as default or initial guess hyperparameters are rarely optimal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eb0754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
