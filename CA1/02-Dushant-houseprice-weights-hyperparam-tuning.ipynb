{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af5fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76eef01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# [cite_start]2. Data Loading and Preprocessing (Reusable Code) [cite: 48]\n",
    "def load_and_preprocess_data(file_path=\"Housing.csv\"):\n",
    "    \"\"\"Loads and prepares the housing data.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # --- Preprocessing Steps ---\n",
    "    for col in [\"mainroad\", \"guestroom\", \"basement\", \"hotwaterheating\", \"airconditioning\", \"prefarea\"]:\n",
    "        df[col] = df[col].map({\"yes\": 1, \"no\": 0})\n",
    "    df = pd.get_dummies(df, columns=[\"furnishingstatus\"], prefix=\"furnish\", drop_first=True)\n",
    "    df.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "    target_scaler = np.mean(df[\"price\"]) / 10\n",
    "    df[\"price\"] = df[\"price\"] / target_scaler\n",
    "\n",
    "    df[\"area_bedroom_ratio\"] = df[\"area\"] / (df[\"bedrooms\"] + 1)\n",
    "\n",
    "    # --- Feature and Target Split ---\n",
    "    X = df.drop(columns=[\"price\"]).values.astype(float)\n",
    "    y = y = df[\"price\"].values.reshape(-1, 1).astype(float)\n",
    "\n",
    "    # --- Normalization ---\n",
    "    X_mean = X.mean(axis=0)\n",
    "    X_std = X.std(axis=0)\n",
    "    X_std[X_std == 0] = 1\n",
    "    X = (X - X_mean) / X_std\n",
    "\n",
    "    # --- Train/Test Split ---\n",
    "    n = X.shape[0]\n",
    "    idx = np.arange(n)\n",
    "    np.random.shuffle(idx)\n",
    "    split = int(n * 0.8)\n",
    "    train_idx, test_idx = idx[:split], idx[split:]\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, target_scaler\n",
    "\n",
    "# Activation and loss functions (can be placed here or inside the main function)\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def drelu(z):\n",
    "    return (z > 0).astype(float)\n",
    "\n",
    "# --- Updated Metric Functions ---\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mse(y_true, y_pred))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b7ab675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hyperparameter Tuning...\n",
      "\n",
      "--- Running combination 1: LR=0.001, Hidden Units=16, Epochs=500 ---\n",
      "Result: Test RMSE = 1,067,157.26 | Test R² = 0.6612 (took 0.04s)\n",
      "✨ New best model found! Previous best RMSE: inf\n",
      "\n",
      "--- Running combination 2: LR=0.001, Hidden Units=16, Epochs=1000 ---\n",
      "Result: Test RMSE = 1,018,892.59 | Test R² = 0.6911 (took 0.09s)\n",
      "✨ New best model found! Previous best RMSE: 1,067,157.26\n",
      "\n",
      "--- Running combination 3: LR=0.001, Hidden Units=16, Epochs=1500 ---\n",
      "Result: Test RMSE = 1,007,337.61 | Test R² = 0.6981 (took 0.12s)\n",
      "✨ New best model found! Previous best RMSE: 1,018,892.59\n",
      "\n",
      "--- Running combination 4: LR=0.001, Hidden Units=32, Epochs=500 ---\n",
      "Result: Test RMSE = 1,045,440.86 | Test R² = 0.6748 (took 0.05s)\n",
      "\n",
      "--- Running combination 5: LR=0.001, Hidden Units=32, Epochs=1000 ---\n",
      "Result: Test RMSE = 1,002,186.22 | Test R² = 0.7012 (took 0.11s)\n",
      "✨ New best model found! Previous best RMSE: 1,007,337.61\n",
      "\n",
      "--- Running combination 6: LR=0.001, Hidden Units=32, Epochs=1500 ---\n",
      "Result: Test RMSE = 1,008,689.56 | Test R² = 0.6973 (took 0.23s)\n",
      "\n",
      "--- Running combination 7: LR=0.001, Hidden Units=64, Epochs=500 ---\n",
      "Result: Test RMSE = 1,020,458.83 | Test R² = 0.6902 (took 0.13s)\n",
      "\n",
      "--- Running combination 8: LR=0.001, Hidden Units=64, Epochs=1000 ---\n",
      "Result: Test RMSE = 999,532.19 | Test R² = 0.7028 (took 0.36s)\n",
      "✨ New best model found! Previous best RMSE: 1,002,186.22\n",
      "\n",
      "--- Running combination 9: LR=0.001, Hidden Units=64, Epochs=1500 ---\n",
      "Result: Test RMSE = 1,002,379.12 | Test R² = 0.7011 (took 0.40s)\n",
      "\n",
      "--- Running combination 10: LR=0.005, Hidden Units=16, Epochs=500 ---\n",
      "Result: Test RMSE = 999,419.32 | Test R² = 0.7028 (took 0.05s)\n",
      "✨ New best model found! Previous best RMSE: 999,532.19\n",
      "\n",
      "--- Running combination 11: LR=0.005, Hidden Units=16, Epochs=1000 ---\n",
      "Result: Test RMSE = 982,885.76 | Test R² = 0.7126 (took 0.15s)\n",
      "✨ New best model found! Previous best RMSE: 999,419.32\n",
      "\n",
      "--- Running combination 12: LR=0.005, Hidden Units=16, Epochs=1500 ---\n",
      "Result: Test RMSE = 984,279.18 | Test R² = 0.7118 (took 0.20s)\n",
      "\n",
      "--- Running combination 13: LR=0.005, Hidden Units=32, Epochs=500 ---\n",
      "Result: Test RMSE = 985,274.14 | Test R² = 0.7112 (took 0.13s)\n",
      "\n",
      "--- Running combination 14: LR=0.005, Hidden Units=32, Epochs=1000 ---\n",
      "Result: Test RMSE = 994,538.91 | Test R² = 0.7057 (took 0.20s)\n",
      "\n",
      "--- Running combination 15: LR=0.005, Hidden Units=32, Epochs=1500 ---\n",
      "Result: Test RMSE = 986,533.78 | Test R² = 0.7104 (took 0.33s)\n",
      "\n",
      "--- Running combination 16: LR=0.005, Hidden Units=64, Epochs=500 ---\n",
      "Result: Test RMSE = 989,699.94 | Test R² = 0.7086 (took 0.22s)\n",
      "\n",
      "--- Running combination 17: LR=0.005, Hidden Units=64, Epochs=1000 ---\n",
      "Result: Test RMSE = 980,952.11 | Test R² = 0.7137 (took 0.43s)\n",
      "✨ New best model found! Previous best RMSE: 982,885.76\n",
      "\n",
      "--- Running combination 18: LR=0.005, Hidden Units=64, Epochs=1500 ---\n",
      "Result: Test RMSE = 980,531.70 | Test R² = 0.7140 (took 0.61s)\n",
      "✨ New best model found! Previous best RMSE: 980,952.11\n",
      "\n",
      "--- Running combination 19: LR=0.0001, Hidden Units=16, Epochs=500 ---\n",
      "Result: Test RMSE = 4,715,632.79 | Test R² = -5.6160 (took 0.08s)\n",
      "\n",
      "--- Running combination 20: LR=0.0001, Hidden Units=16, Epochs=1000 ---\n",
      "Result: Test RMSE = 4,336,569.52 | Test R² = -4.5951 (took 0.13s)\n",
      "\n",
      "--- Running combination 21: LR=0.0001, Hidden Units=16, Epochs=1500 ---\n",
      "Result: Test RMSE = 3,885,336.49 | Test R² = -3.4913 (took 0.13s)\n",
      "\n",
      "--- Running combination 22: LR=0.0001, Hidden Units=32, Epochs=500 ---\n",
      "Result: Test RMSE = 4,712,723.65 | Test R² = -5.6079 (took 0.06s)\n",
      "\n",
      "--- Running combination 23: LR=0.0001, Hidden Units=32, Epochs=1000 ---\n",
      "Result: Test RMSE = 4,305,871.69 | Test R² = -4.5162 (took 0.12s)\n",
      "\n",
      "--- Running combination 24: LR=0.0001, Hidden Units=32, Epochs=1500 ---\n",
      "Result: Test RMSE = 3,935,409.77 | Test R² = -3.6078 (took 0.14s)\n",
      "\n",
      "--- Running combination 25: LR=0.0001, Hidden Units=64, Epochs=500 ---\n",
      "Result: Test RMSE = 4,708,820.55 | Test R² = -5.5969 (took 0.12s)\n",
      "\n",
      "--- Running combination 26: LR=0.0001, Hidden Units=64, Epochs=1000 ---\n",
      "Result: Test RMSE = 4,273,562.82 | Test R² = -4.4337 (took 0.18s)\n",
      "\n",
      "--- Running combination 27: LR=0.0001, Hidden Units=64, Epochs=1500 ---\n",
      "Result: Test RMSE = 3,533,276.79 | Test R² = -2.7143 (took 0.32s)\n",
      "\n",
      "========================================\n",
      "Hyperparameter Tuning Complete!\n",
      "========================================\n",
      "\n",
      "Best Hyperparameters Found:\n",
      "{\n",
      "    \"learning_rate\": 0.005,\n",
      "    \"hidden_units\": 64,\n",
      "    \"epochs\": 1500\n",
      "}\n",
      "\n",
      "Performance of Best Model:\n",
      "{\n",
      "    \"mse\": 961442407815.7543,\n",
      "    \"rmse\": 980531.6964870408,\n",
      "    \"mae\": 734578.5801903749,\n",
      "    \"r2\": 0.7139508056952387\n",
      "}\n",
      "\n",
      "Best model weights saved in 'best_model/' directory.\n",
      "Best model details saved to 'best_model/best_model_details.json'.\n",
      "\n",
      "--- Conclusion ---\n",
      "The hyperparameter tuning process systematically evaluated multiple combinations of learning rates, hidden units, and epochs.\n",
      "The baseline model (from Notebook 1) might have had a decent performance, but by exploring different configurations, we found a model with a lower Test RMSE, indicating better predictive accuracy.\n",
      "The best model, with LR=0.005, Hidden Units=64, and 1500 epochs, provides a more optimized solution for this dataset.\n",
      "This demonstrates the critical importance of tuning, as default or initial guess hyperparameters are rarely optimal.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# [cite_start]3. Define Trainable Model Function [cite: 49]\n",
    "def train_model(X_train, y_train, X_test, y_test, learning_rate, n_hidden, n_epochs, target_scaler):\n",
    "    \"\"\"\n",
    "    A function that takes hyperparameters, trains a model, and returns performance.\n",
    "    \"\"\"\n",
    "    input_size = X_train.shape[1]\n",
    "    output_size = 1\n",
    "\n",
    "    # Initialize weights\n",
    "    W1 = np.random.randn(input_size, n_hidden) * 0.01\n",
    "    b1 = np.zeros((1, n_hidden))\n",
    "    W2 = np.random.randn(n_hidden, output_size) * 0.01\n",
    "    b2 = np.zeros((1, output_size))\n",
    "\n",
    "    # Training loop\n",
    "    for ep in range(n_epochs):\n",
    "        # Forward pass\n",
    "        z1 = X_train.dot(W1) + b1\n",
    "        a1 = relu(z1)\n",
    "        z2 = a1.dot(W2) + b2\n",
    "        y_pred = z2\n",
    "\n",
    "        # Backpropagation\n",
    "        dz2 = (y_pred - y_train) * (2 / y_train.shape[0])\n",
    "        dW2 = a1.T.dot(dz2)\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True)\n",
    "        da1 = dz2.dot(W2.T)\n",
    "        dz1 = da1 * drelu(z1)\n",
    "        dW1 = X_train.T.dot(dz1)\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True)\n",
    "\n",
    "        # Update parameters\n",
    "        W1 -= learning_rate * dW1\n",
    "        b1 -= learning_rate * db1\n",
    "        W2 -= learning_rate * dW2\n",
    "        b2 -= learning_rate * db2\n",
    "\n",
    "    # Evaluation on the test set\n",
    "    test_preds_scaled = relu(X_test.dot(W1) + b1).dot(W2) + b2\n",
    "    \n",
    "    # Rescale to original price units for metrics\n",
    "    test_preds_actual = test_preds_scaled * target_scaler\n",
    "    y_test_actual = y_test * target_scaler\n",
    "\n",
    "    # [cite_start]--- Calculate all regression metrics --- [cite: 38]\n",
    "    metrics = {\n",
    "        \"mse\": mse(y_test_actual, test_preds_actual),\n",
    "        \"rmse\": rmse(y_test_actual, test_preds_actual),\n",
    "        \"mae\": mae(y_test_actual, test_preds_actual),\n",
    "        \"r2\": r2_score(y_test_actual, test_preds_actual)\n",
    "    }\n",
    "    \n",
    "    model_weights = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
    "    \n",
    "    return metrics, model_weights\n",
    "\n",
    "\n",
    "# [cite_start]4. Hyperparameter Tuning (Manual) [cite: 51]\n",
    "print(\"Starting Hyperparameter Tuning...\")\n",
    "\n",
    "# Load data once\n",
    "X_train, X_test, y_train, y_test, target_scaler = load_and_preprocess_data()\n",
    "\n",
    "# [cite_start]Define hyperparameter search space [cite: 52, 53, 54, 56]\n",
    "learning_rates = [0.001, 0.005,0.0001]\n",
    "hidden_units = [16, 32,64]\n",
    "epochs_list = [500, 1000,1500]\n",
    "\n",
    "results = []\n",
    "best_rmse = float('inf')\n",
    "best_hyperparams = {}\n",
    "best_model_weights = {}\n",
    "\n",
    "# [cite_start]--- Nested loops to test combinations --- [cite: 58]\n",
    "run_number = 1\n",
    "for lr in learning_rates:\n",
    "    for hidden in hidden_units:\n",
    "        for epochs in epochs_list:\n",
    "            start_time = time.time()\n",
    "            print(f\"\\n--- Running combination {run_number}: LR={lr}, Hidden Units={hidden}, Epochs={epochs} ---\")\n",
    "            \n",
    "            # Train the model with the current set of hyperparameters\n",
    "            current_metrics, current_weights = train_model(\n",
    "                X_train, y_train, X_test, y_test, \n",
    "                learning_rate=lr, n_hidden=hidden, n_epochs=epochs, \n",
    "                target_scaler=target_scaler\n",
    "            )\n",
    "            \n",
    "            end_time = time.time()\n",
    "            # --- Updated print statement to show multiple metrics ---\n",
    "            print(f\"Result: Test RMSE = {current_metrics['rmse']:,.2f} | Test R² = {current_metrics['r2']:.4f} (took {end_time - start_time:.2f}s)\")\n",
    "            \n",
    "            # [cite_start]Track performance for each combination [cite: 58]\n",
    "\n",
    "            run_info = {\n",
    "                'learning_rate': lr,\n",
    "                'hidden_units': hidden,\n",
    "                'epochs': epochs,\n",
    "                'metrics': current_metrics\n",
    "            }\n",
    "            results.append(run_info)\n",
    "\n",
    "            # Check if this is the best model so far based on RMSE\n",
    "            if current_metrics['rmse'] < best_rmse:\n",
    "                print(f\"✨ New best model found! Previous best RMSE: {best_rmse:,.2f}\")\n",
    "                best_rmse = current_metrics['rmse']\n",
    "                best_hyperparams = run_info\n",
    "                best_model_weights = current_weights\n",
    "            \n",
    "            run_number += 1\n",
    "\n",
    "# [cite_start]5. Best Model [cite: 59]\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"Hyperparameter Tuning Complete!\")\n",
    "print(\"=\"*40)\n",
    "# --- Updated to display all metrics for the best model ---\n",
    "print(\"\\nBest Hyperparameters Found:\")\n",
    "best_info_to_print = {k: v for k, v in best_hyperparams.items() if k != 'metrics'}\n",
    "print(json.dumps(best_info_to_print, indent=4))\n",
    "print(\"\\nPerformance of Best Model:\")\n",
    "print(json.dumps(best_hyperparams.get('metrics', {}), indent=4))\n",
    "\n",
    "\n",
    "# [cite_start]6. Save Best Model & Results [cite: 62]\n",
    "# Create a directory for the best model's artifacts\n",
    "os.makedirs(\"best_model\", exist_ok=True)\n",
    "\n",
    "# [cite_start]Save the weights of the best model [cite: 63]\n",
    "for name, weights in best_model_weights.items():\n",
    "    np.save(f\"best_model/{name}.npy\", weights)\n",
    "print(\"\\nBest model weights saved in 'best_model/' directory.\")\n",
    "\n",
    "# [cite_start]Save the best hyperparameters and results to a JSON file [cite: 63]\n",
    "with open(\"best_model/best_model_details.json\", \"w\") as f:\n",
    "    # Convert numpy float types to standard python floats for JSON serialization\n",
    "    serializable_hyperparams = best_hyperparams.copy()\n",
    "    serializable_hyperparams['metrics'] = {k: float(v) for k, v in serializable_hyperparams['metrics'].items()}\n",
    "    json.dump(serializable_hyperparams, f, indent=4)\n",
    "print(\"Best model details saved to 'best_model/best_model_details.json'.\")\n",
    "\n",
    "\n",
    "# [cite_start]7. Conclusion [cite: 65]\n",
    "print(\"\\n--- Conclusion ---\")\n",
    "print(\"The hyperparameter tuning process systematically evaluated multiple combinations of learning rates, hidden units, and epochs.\")\n",
    "print(\"The baseline model (from Notebook 1) might have had a decent performance, but by exploring different configurations, we found a model with a lower Test RMSE, indicating better predictive accuracy.\")\n",
    "print(f\"The best model, with LR={best_hyperparams['learning_rate']}, Hidden Units={best_hyperparams['hidden_units']}, and {best_hyperparams['epochs']} epochs, provides a more optimized solution for this dataset.\")\n",
    "print(\"This demonstrates the critical importance of tuning, as default or initial guess hyperparameters are rarely optimal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eb0754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
